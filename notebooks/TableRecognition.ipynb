{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a60cee9a",
   "metadata": {},
   "source": [
    "# Algorithm Extension: Table Recognition\n",
    "\n",
    "One of the downsides of the current algorithm is that it has trouble with tables, as these resemble the border class that we detect in the algorithm. In this notebook we first check the extent of this problem, and also propose a fix that we can make to the model so that we can avoid these errors. We  decided against changing the detection of the border class, as this would mean we would sacrifice recall. Instead we opt for the approach of detecting whether a page contains a table, after which we ignore this page for the further steps in the algorithm, avoiding these false positives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "07421623",
   "metadata": {},
   "outputs": [],
   "source": [
    "import img2table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2bf13f07",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'img2table' has no attribute 'version'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mimg2table\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mversion\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'img2table' has no attribute 'version'"
     ]
    }
   ],
   "source": [
    "img2table.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fddc8bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f6f97b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install img2table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e52956",
   "metadata": {},
   "source": [
    "## Examining the problem\n",
    "\n",
    "The first step is to see the extent of the problem. For this we will be taking a set of 'inventarislijsten' from the corpus, of which we know that they contain tables, and get the statistics on the number of redacted text and regions, as well as to examine a few ourselves. Because it would take a very long time run it on all these PDF files we are going to run it on a sample and see the output that we get. In principle this should be equal to 0 for the number of redacted blocks, as these tables should not be detected. Of course sometimes some information in tables is redacted, but this is relatively low so we should be able to see that something is wrong on a page level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d2396891",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['python', '../scripts/run_redaction_detector.py', '--pdf_path', '../debug_data/maik_example.pdf', '--output_path', '../debug_data/maik_out.pdf', '--exclude_tables', 'True'], returncode=0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.run(['python', '../scripts/run_redaction_detector.py', '--pdf_path',\n",
    "                   '../debug_data/maik_example.pdf', '--output_path', '../debug_data/maik_out.pdf',\n",
    "               '--exclude_tables', 'True'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38ecaffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 13/13 [05:35<00:00, 25.78s/it]\n"
     ]
    }
   ],
   "source": [
    "# I have put the data into 'debug_data/images'\n",
    "# Now we run our script over all of the images.\n",
    "for image in tqdm(glob('../debug_data/table_pdfs/*')):\n",
    "    output_path = '../debug_data/table_pdfs_output/' + image.split('/')[-1]\n",
    "    subprocess.run(['python', '../scripts/run_redaction_detector.py', '--pdf_path',\n",
    "                   image, '--output_path', output_path])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e4a09c",
   "metadata": {},
   "source": [
    "Now that we have run the code over a few input pdfs we will get the statistics of all of them, create a complete dataframe and get the statistics for all the pdfs combined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ddb70a82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of redacted regions</th>\n",
       "      <th>Percentage of redacted text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>169.000000</td>\n",
       "      <td>169.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.426036</td>\n",
       "      <td>13.899408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>12.535028</td>\n",
       "      <td>28.651777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>80.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Number of redacted regions  Percentage of redacted text\n",
       "count                  169.000000                   169.000000\n",
       "mean                     4.426036                    13.899408\n",
       "std                     12.535028                    28.651777\n",
       "min                      0.000000                     0.000000\n",
       "25%                      0.000000                     0.000000\n",
       "50%                      0.000000                     0.000000\n",
       "75%                      1.000000                     0.000000\n",
       "max                     80.000000                   100.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_csv_files = glob('../debug_data/table_pdfs_output/*.csv')\n",
    "redaction_output_dataframe = pd.concat([pd.read_csv(path) for path in all_csv_files])\n",
    "redaction_output_dataframe.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17fa33bf",
   "metadata": {},
   "source": [
    "Although not incredibly high, these percentages are still too high, as there should not be any redacted text in these pages at all. In the next part of the notebook we will attempt to fix this problem. What did stand out is that the problem seemed to mostly be around tables that did not fill the entire page, this makes sense, as we specifically only consider boxes where the width is larger than the hight, for full page tables this will not be the case most of the times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e10d1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "from pdf2image import convert_from_path\n",
    "from img2table.document import Image as TableImage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af43f087",
   "metadata": {},
   "source": [
    "Let's experiment with a specific document that we know contains some tables the we should discard but that are not discarded, and see if we can do this with the `img2table` package. In the following example all pages contain a table, but about half of them are seen as redacted text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663dea2f",
   "metadata": {},
   "source": [
    "## Solving the problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b57e5b1",
   "metadata": {},
   "source": [
    "We are going to be detecting tables using the `img2table` package, and skipping these tables when we detect a table, as with the approach shown above, where we restrict on having a table larger than at least half of the page width. We will set the statistics for these pages to zero so that we get an idea of the improvement we have over the original method. The code has been implemented in the algorithm itself, and we will test it below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee26ffbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = convert_from_path('../debug_data/table_pdfs_output/Schiphol deel 1.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e66bf498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page-1 True\n",
      "page-2 True\n",
      "page-3 True\n",
      "page-4 True\n",
      "page-5 True\n",
      "page-6 True\n",
      "page-7 True\n",
      "page-8 True\n",
      "page-9 False\n",
      "page-10 True\n",
      "page-11 True\n",
      "page-12 True\n",
      "page-13 True\n",
      "page-14 True\n",
      "page-15 True\n"
     ]
    }
   ],
   "source": [
    "# Go through all pages and see if they contain a table according to our rules.\n",
    "for i, image in enumerate(images):\n",
    "    byte_image = io.BytesIO()\n",
    "    # image.save expects a file-like as a argument\n",
    "    image.save(byte_image, format=image.format)\n",
    "    # Turn the BytesIO object back into a bytes object\n",
    "    byte_image = byte_image.getvalue()\n",
    "    table_image = TableImage(src=byte_image)\n",
    "    # Table identification\n",
    "    image_tables = table_image.extract_tables()\n",
    "    # This module is recall oriented so we should require the tables to be of a larger size\n",
    "    page_width, page_height = image.size\n",
    "    detected_tables = []\n",
    "    for table in image_tables:\n",
    "        table_width = table.bbox.x2 - table.bbox.x1\n",
    "        table_height = table.bbox.y2 - table.bbox.y1\n",
    "        # is the size of the table in pixels big enough compared to the complete page?\n",
    "        if (table_width / page_width) > 0.50 and table_height > 50:\n",
    "            # now check the number of cells\n",
    "            if ((table.df.shape[0] >= 2) and (table.df.shape[1] >=3)):\n",
    "                detected_tables.append(True)\n",
    "        \n",
    "    print('page-%d' % (i+1), any(detected_tables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c8701a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 13/13 [02:01<00:00,  9.35s/it]\n"
     ]
    }
   ],
   "source": [
    "# and now on the tables with our algorithm\n",
    "for image in tqdm(glob('../debug_data/table_pdfs/*')):\n",
    "    output_path = '../debug_data/table_pdfs_output/' + image.split('/')[-1]\n",
    "    subprocess.run(['python', '../scripts/run_redaction_detector.py', '--pdf_path',\n",
    "                   image, '--output_path', output_path, '--exclude_tables', 'True'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80cf5862",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of redacted regions</th>\n",
       "      <th>Percentage of redacted text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>169.000000</td>\n",
       "      <td>169.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.650888</td>\n",
       "      <td>6.230769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>10.256938</td>\n",
       "      <td>20.777735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>80.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Number of redacted regions  Percentage of redacted text\n",
       "count                  169.000000                   169.000000\n",
       "mean                     2.650888                     6.230769\n",
       "std                     10.256938                    20.777735\n",
       "min                      0.000000                     0.000000\n",
       "25%                      0.000000                     0.000000\n",
       "50%                      0.000000                     0.000000\n",
       "75%                      0.000000                     0.000000\n",
       "max                     80.000000                   100.000000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_csv_files = glob('../debug_data/table_pdfs_output/*.csv')\n",
    "redaction_output_dataframe = pd.concat([pd.read_csv(path) for path in all_csv_files])\n",
    "redaction_output_dataframe.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162ffc1f",
   "metadata": {},
   "source": [
    "This seems to work very well for the tables, but we should also make sure that it does not compromise the ability of our algorithm in detecting other boxes, i.e. that it skips too many pages and we our recall drops. For this we will take several PDF files that do not have any tables, and we compare the original and the updated algorithm on both numbers, these are in the `clean_data` folder. We will again take an example first."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3562fa9",
   "metadata": {},
   "source": [
    "## Testing Method Recall\n",
    "\n",
    "To test the recall of the method and check that we are not losing pages that do not contain tables we will test our method on a set of pdf files of which we know that there are no tables present, and therefore the statistics on the dataset should not change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "535f1b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = convert_from_path('../debug_data/clean_data/Binder OneLove.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80e4ce95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page-1 False\n",
      "page-2 False\n",
      "page-3 False\n",
      "page-4 False\n",
      "page-5 False\n",
      "page-6 False\n",
      "page-7 False\n",
      "page-8 False\n",
      "page-9 False\n",
      "page-10 True\n",
      "page-11 False\n",
      "page-12 False\n",
      "page-13 False\n",
      "page-14 False\n",
      "page-15 False\n",
      "page-16 False\n",
      "page-17 False\n",
      "page-18 False\n",
      "page-19 False\n",
      "page-20 True\n",
      "page-21 False\n",
      "page-22 True\n",
      "page-23 True\n",
      "page-24 True\n",
      "page-25 False\n"
     ]
    }
   ],
   "source": [
    "# Go through all pages and see if they contain a table according to our rules.\n",
    "for i, image in enumerate(images):\n",
    "    byte_image = io.BytesIO()\n",
    "    # image.save expects a file-like as a argument\n",
    "    image.save(byte_image, format=image.format)\n",
    "    # Turn the BytesIO object back into a bytes object\n",
    "    byte_image = byte_image.getvalue()\n",
    "    table_image = TableImage(src=byte_image)\n",
    "    # Table identification\n",
    "    image_tables = table_image.extract_tables()\n",
    "    # This module is recall oriented so we should require the tables to be of a larger size\n",
    "    page_width, page_height = image.size\n",
    "    detected_tables = []\n",
    "    for table in image_tables:\n",
    "        table_width = table.bbox.x2 - table.bbox.x1\n",
    "        table_height = table.bbox.y2 - table.bbox.y1\n",
    "        # is the size of the table in pixels big enough compared to the complete page?\n",
    "        if (table_width / page_width) > 0.50 and table_height > 50:\n",
    "            # now check the number of cells\n",
    "            if ((table.df.shape[0] >= 2) and (table.df.shape[1] >=3)):\n",
    "                detected_tables.append(True)\n",
    "        \n",
    "    print('page-%d' % (i+1), any(detected_tables))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce4bcf1",
   "metadata": {},
   "source": [
    "We are getting a few false positives that we should actually keep, but this particular document only contains the more difficult border class, which is the one that will get confused as a table the most often, so it is actually quite goo as it is. Let's run the full experiment in the clean pages and see the differences between discarding table pages and not discarding table pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9130bb5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████████████████████▌                       | 7/15 [04:29<05:00, 37.54s/it]/Users/rubenvanheusden/anaconda3/envs/text_redaction_env/lib/python3.11/site-packages/numpy/core/fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/rubenvanheusden/anaconda3/envs/text_redaction_env/lib/python3.11/site-packages/numpy/core/_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      " 80%|██████████████████████████████████▍        | 12/15 [07:13<01:46, 35.52s/it]/Users/rubenvanheusden/anaconda3/envs/text_redaction_env/lib/python3.11/site-packages/numpy/core/fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/rubenvanheusden/anaconda3/envs/text_redaction_env/lib/python3.11/site-packages/numpy/core/_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/Users/rubenvanheusden/anaconda3/envs/text_redaction_env/lib/python3.11/site-packages/numpy/core/fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/rubenvanheusden/anaconda3/envs/text_redaction_env/lib/python3.11/site-packages/numpy/core/_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/Users/rubenvanheusden/anaconda3/envs/text_redaction_env/lib/python3.11/site-packages/numpy/core/fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/rubenvanheusden/anaconda3/envs/text_redaction_env/lib/python3.11/site-packages/numpy/core/_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "100%|███████████████████████████████████████████| 15/15 [11:23<00:00, 45.56s/it]\n"
     ]
    }
   ],
   "source": [
    "for image in tqdm(glob('../debug_data/clean_data/*')):\n",
    "    output_path = '../debug_data/clean_data_output/' + image.split('/')[-1]\n",
    "    subprocess.run(['python', '../scripts/run_redaction_detector.py', '--pdf_path',\n",
    "                   image, '--output_path', output_path])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5be786f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of redacted regions</th>\n",
       "      <th>Percentage of redacted text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>279.000000</td>\n",
       "      <td>279.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9.179211</td>\n",
       "      <td>23.892473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>13.559228</td>\n",
       "      <td>27.598403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>13.000000</td>\n",
       "      <td>46.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>103.000000</td>\n",
       "      <td>99.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Number of redacted regions  Percentage of redacted text\n",
       "count                  279.000000                   279.000000\n",
       "mean                     9.179211                    23.892473\n",
       "std                     13.559228                    27.598403\n",
       "min                      0.000000                     0.000000\n",
       "25%                      0.000000                     0.000000\n",
       "50%                      4.000000                    10.000000\n",
       "75%                     13.000000                    46.000000\n",
       "max                    103.000000                    99.000000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_csv_files = glob('../debug_data/clean_data_output/*.csv')\n",
    "redaction_output_dataframe = pd.concat([pd.read_csv(path) for path in all_csv_files])\n",
    "redaction_output_dataframe.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd49473",
   "metadata": {},
   "source": [
    "Now we compare this to the version where we exclude tables, and see the difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "73a5edb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████████████████████▌                       | 7/15 [05:04<05:46, 43.29s/it]/Users/rubenvanheusden/anaconda3/envs/text_redaction_env/lib/python3.11/site-packages/numpy/core/fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/rubenvanheusden/anaconda3/envs/text_redaction_env/lib/python3.11/site-packages/numpy/core/_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      " 80%|██████████████████████████████████▍        | 12/15 [08:17<02:05, 41.79s/it]Traceback (most recent call last):\n",
      "  File \"/Users/rubenvanheusden/Desktop/AronTextRedaction/TPDLTextRedaction/notebooks/../scripts/run_redaction_detector.py\", line 90, in <module>\n",
      "    main(args)\n",
      "  File \"/Users/rubenvanheusden/Desktop/AronTextRedaction/TPDLTextRedaction/notebooks/../scripts/run_redaction_detector.py\", line 50, in main\n",
      "    image_tables = table_image.extract_tables()\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/rubenvanheusden/anaconda3/envs/text_redaction_env/lib/python3.11/site-packages/img2table/document/image.py\", line 41, in extract_tables\n",
      "    extracted_tables = super(Image, self).extract_tables(ocr=ocr,\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/rubenvanheusden/anaconda3/envs/text_redaction_env/lib/python3.11/site-packages/img2table/document/base/__init__.py\", line 71, in extract_tables\n",
      "    tables = {idx: TableImage(img=img,\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/rubenvanheusden/anaconda3/envs/text_redaction_env/lib/python3.11/site-packages/img2table/document/base/__init__.py\", line 73, in <dictcomp>\n",
      "    min_confidence=min_confidence).extract_tables(implicit_rows=implicit_rows,\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/rubenvanheusden/anaconda3/envs/text_redaction_env/lib/python3.11/site-packages/img2table/tables/image.py\", line 135, in extract_tables\n",
      "    self.extract_bordered_tables(implicit_rows=implicit_rows)\n",
      "  File \"/Users/rubenvanheusden/anaconda3/envs/text_redaction_env/lib/python3.11/site-packages/img2table/tables/image.py\", line 73, in extract_bordered_tables\n",
      "    h_lines, v_lines = detect_lines(image=self.img,\n",
      "    ^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/rubenvanheusden/anaconda3/envs/text_redaction_env/lib/python3.11/site-packages/img2table/tables/processing/bordered_tables/lines.py\", line 240, in detect_lines\n",
      "    thresh = threshold_dark_areas(img=img, char_length=char_length)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/rubenvanheusden/anaconda3/envs/text_redaction_env/lib/python3.11/site-packages/img2table/tables/processing/bordered_tables/lines.py\", line 28, in threshold_dark_areas\n",
      "    blur = cv2.medianBlur(img, blur_size)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "cv2.error: OpenCV(4.6.0) /Users/ec2-user/ci_py311/opencv-suite_1678377996177/work/modules/imgproc/src/median_blur.simd.hpp:241: error: (-215:Assertion failed) k < 16 in function 'medianBlur_8u_O1'\n",
      "\n",
      "100%|███████████████████████████████████████████| 15/15 [13:02<00:00, 52.19s/it]\n"
     ]
    }
   ],
   "source": [
    "for image in tqdm(glob('../debug_data/clean_data/*')):\n",
    "    output_path = '../debug_data/clean_data_output/' + image.split('/')[-1]\n",
    "    subprocess.run(['python', '../scripts/run_redaction_detector.py', '--pdf_path',\n",
    "                   image, '--output_path', output_path, '--exclude_tables', 'True'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2421e687",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of redacted regions</th>\n",
       "      <th>Percentage of redacted text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>279.000000</td>\n",
       "      <td>279.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8.286738</td>\n",
       "      <td>21.623656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>12.973002</td>\n",
       "      <td>26.866007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>11.000000</td>\n",
       "      <td>42.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>103.000000</td>\n",
       "      <td>99.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Number of redacted regions  Percentage of redacted text\n",
       "count                  279.000000                   279.000000\n",
       "mean                     8.286738                    21.623656\n",
       "std                     12.973002                    26.866007\n",
       "min                      0.000000                     0.000000\n",
       "25%                      0.000000                     0.000000\n",
       "50%                      3.000000                     6.000000\n",
       "75%                     11.000000                    42.000000\n",
       "max                    103.000000                    99.000000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_csv_files = glob('../debug_data/clean_data_output/*.csv')\n",
    "redaction_output_dataframe = pd.concat([pd.read_csv(path) for path in all_csv_files])\n",
    "redaction_output_dataframe.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb62264",
   "metadata": {},
   "source": [
    "As we can see from the above dataframe, the number of detected redacted blocks and perdentage is pretty consistent with the version where we don't exlcude tables, meaning that we are nog getting a lot of false positives. If anything we are detecting tables a bit too much but it is quite close to the original version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca1e899",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "text_redaction_env",
   "language": "python",
   "name": "text_redaction_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
